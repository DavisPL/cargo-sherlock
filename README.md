# Cargo-Sherlock Artifact üïµÔ∏è
`Cargo-Sherlock` (alternative name RHS for Rust Sherlock Holmes) is a Python-based tool designed to enhance the security of Rust projects by leveraging different metadata information about Rust crates. It is an automated reasoning tool that attempts to determine the safety of Rust crates by modeling trust. 
This repository contains the artifact for paper[] submitted to FORMALISE 2026. 

## Installation

For the installation, you can either follow the steps below or download our pre-configured Virtual Machine with all dependencies installed from [Cargo Sherlock VM](). If you downloaded the VM, you can skip step 1-5. 

1. Clone this repository and the [cargo-scan](https://github.com/PLSysSec/cargo-scan) submodule.
```Bash
git clone --recurse-submodules https://github.com/muhammad-hassnain/cargo-sherlock-artifact
```
2. Install Rust via the [official website](https://www.rust-lang.org/tools/install). After installing Rust, you can verify the installation by running:
```Bash
rustc --version
```
This should display the installed Rust version.

3. Ensure you have Python 3 installed. You can verify your Python installation by running:
```Bash
python3 --version
```
This should display the installed Python version. If not installed, you can download it from the [official website](https://www.python.org/downloads/).

4. Run `make` to create a Python virtual environment, this will install all Python dependencies, activate the virtual environment, and build cargo-scan.
```Bash
make
```

This should take 3-5 minutes and will prompt you for your GitHub personal access token (see step 5 below).

5. You can Generate a GitHub personal access token from [token page](https://github.com/settings/tokens/new). Please select Generate new token (classic). Then, name your token, select an expiration date, and grant the token at least the `public_repo` scope by checking the box. Finally, create and copy your token and paste it. In case, you didn't provide a token at installation time, you can create the file `helpers/token.txt` and paste your token there later.

6. You can activate the python virtual environment by running: 
```bash
source .venv/bin/activate 
```
You should now see a `(.venv)` prefix in your terminal indicating that the virtual environment is active.

You can check your installation is successful by running:
```bash
python3 sherlock.py trust anyhow 1.0.97
```
You should see something like:
 
![image here](output.png "Screenshot from 10/30")


## Replication Instructions


We provide you with step-by-step instructions and scripts to replicate the results for each research question (RQ) presented in the paper.

### RQ1: Synthetic Typosquatted Attacks

This experiment involves running Cargo-Sherlock on top 100 frequently downloaded crates from crates.io and generating synthetic typosquatted versions of these crates, running Cargo-Sherlock on them, and analyzing the results. We provide you a list of top 100 crates from the time of our experiments in the file named `top100_crates.csv`. You can run the evaluation script for RQ1 with:

```Bash
python3 eval_rq1.py
```
This default command will use our cached results to generate the heatmap stored in `severity_heatmap.pdf`. However, we provide you with three different modes to run this experiment based on your time and resource availability:

1. Full Experiment (Expected to take around _ hours):
```Bash
python3 eval_rq1.py -m full
```
This version will run Cargo-Sherlock on top 100 crates, create their typosquatted versions, run Cargo-Sherlock on these typosquatted crates, and analyze the results to produce the Heatmap seen in the paper (Figure 5a).

2. Partial Experiment using Existing Crates (Expected to take around _ minutes):
```Bash
python3 eval_rq1.py -m partial 
```
This version will skip the recreating of synthetic typosquatted crates and will use the already provided files in `local_crates/typo_crates` directory. It will run Cargo-Sherlock on these crates and analyze the results to produce the Heatmap seen in the paper (Figure 5a).

3. Most Efficient Experiment using Pre-computed Results (Expected to take around _ minutes):
```Bash
python3 eval_rq1.py -m cache
```
This version will skip both the recreating of synthetic typosquatted crates and running Cargo-Sherlock on them. It will use the already computed csv files generated by parsing the ouputs of Cargo-Sherlock stored in `evaluation/rq1/` directory. It will directly analyze these results to produce the Heatmap seen in the paper (Figure 5a).

### RQ2: Real-World Supply Chain Risks
We will replicate the experiment and the regenerate the figure 5(b) presented in the paper. The source code for faster_log crate is not publicly available on crates.io, therefore, we have included the source code for it in the `local_crates` directory. For faster_log, we will use the local path to analyze it, for other crates, we will fetch them from crates.io.

```Bash
python3 eval_rq2.py
```
This experiment is expected to take around _ minutes to run so we do not provide any caching or partial modes for this experiment. The table will be printed on the terminal and also saved to `rq2_results.txt`. This plot corresponds to the severity heatmap presented in Figure 5(b) in the paper.

### RQ3:

For this we need to disable the assumptions made in Cargo-Sherlock about RustSec advisories. For this , please follow the steps below:
1. Open the file `solver.py` in a text editor.
2. Comment out the line 139-144 and 151-160. These lines are responsible for adding assumptions based on RustSec advisories. We do not want these assumptions to be included in our analysis for RQ3.
3. Save the file after making these changes.
Now, we can run the evaluation script for RQ3:
```Bash
python3 eval_rq3.py
``` 
4. This should generate the plots `rustsec-distribution.pdf` and `rustsec-percentiles.pdf` in the current directory. These plots correspond to the distribution of RustSec advisories grouped by Cargo-Sherlock labels and the distribution of downloads for crates with RustSec advisories, respectively and are Figure 6(a) and Figure 6(b) in the paper.

### RQ4:

For this first we will revert the changes made in step 2 of RQ3 to re-enable the assumptions based on RustSec advisories. For this please open the file `solver.py` in a text editor and uncomment the lines 
139-144 and 151-160. Save the file after making these changes. This question aims to evaluate the perforance of algorithms so we already provide you with the log file output for the crates, so we only measure the time taken by the algorithms to solve the mintrust problem.

This is expected to take 3 hours to run the Horn algorithm on random 1000 crates and another _ hours to to run the Naive algorithm on the same set of crates. We can also provide you with the pre-computed CSV files if needed. You can run the evaluation script for RQ4:
```Bash
python3 eval_rq4.py --use-cache
```
This will read the time taken from our pre computed CSV files and generate the CDF showing the time taken by both algorithms. The output plot `rq4-cdf.pdf`. This will also generate the dependency count plot with the exponential fit as seen in Fiegure 7(b) in the paper. This is expected to take around _ minutes to run.

You can also replicate the experiment on a shorter set of crates namely 100, by providing the `--top 100` argument to the script. This should take around _ hours for Horn algorithm and _ hours for Naive algorithm.
```Bash
python3 eval_rq4.py --no-cache --top 100
```
